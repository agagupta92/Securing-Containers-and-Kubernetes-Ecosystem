8.Additional Security Considerations


Infrastructure security

- So far, we assumed that the Kubernetes cluster was already installed on hardware infrastructure. The underlying infrastructure, whether it is your on premise data center or the public cloud is the backbone of your Kubernetes cluster. The infrastructure provides the foundational compute, memory, storage and networking capabilities to run Kubernetes. The security of this infrastructure is critical. There is an implied trust between Kubernetes and the infrastructure. Even if you secure your applications and the cluster, the underlying infrastructure may still be vulnerable. The vulnerabilities in the infrastructure can be a reason your application or cluster might be compromised. But who is responsible for the security of the infrastructure? Well, that depends on the Kubernetes deployment model. When it comes to deploying Kubernetes, there are two ends of the spectrum. On one hand you have the fully managed Kubernetes solutions. These solutions make it easy to deploy and manage Kubernetes clusters. Some examples are, Azure Kubernetes Service, Amazon's Elastic Container Service and Google Kubernetes Engine. On the other hand, you have a deployment of Kubernetes in your own data center. In this model, you are responsible for managing and operating the Kubernetes clusters. You're also responsible for running the infrastructure as well. Other deployments are in between these two options. The deployment model also governs security responsibilities. In an on premise model, you are responsible for implementing the security controls such as network protection, firewalls, access management, all by yourself. In the managed service model, you still need to implement these security controls. But the difference is that you leverage the capabilities offered by the cloud provider. Some examples of these capabilities are access and resource management and cloud security policies and so on. Moreover, the cloud provider is already responsible for protecting the underlying hardware as per the shared security responsibility model. Regardless of the deployment model, there are some security considerations you must keep in sight. And then work with your infrastructure provider or team to ensure that security implementation addresses these. Make sure there is network isolation among multiple clusters. Access to the Kubernetes control plane should not be permitted directly via the public facing IP addresses. Any access must be limited. Direct public access to nodes should be prohibited. Access must be managed via the control plane using the appropriate services offered by Kubernetes. For Kubernetes to do its job, it needs access to your infrastructure API. Give Kubernetes only as much as API access as needed. Monitor your infrastructure and clusters. Look for anomalies and patterns that impact CIA triad that is confidentiality, integrity and availability. New technologies and approaches to modern cloud native security are emerging. Do your due diligence and adopt as appropriate for your enterprise. Learn more about leveraging artificial intelligence and machine learning for security in this course on LinkedIn Learning.


Logging and monitoring

- When your applications are running and the cluster is humming, you need a way to know what's going on with your Kubernetes' components and applications. Logs are your eyes in your cluster. These logs help debug problems with your cluster. They're also important in detecting security anomalies and any ongoing attacks. However, unlike traditional applications, pods and microservices come and go. They could be stopped and restarted anytime. Furthermore, there's no guarantee that a pod will be started on the same node. After a pod or a node is stopped, you still want the ability to access logs. So your logging lifecycle should be decoupled from that of containers, pods and nodes. Kubernetes doesn't provide any native log management solution. Fortunately, several external logging solutions can be integrated with your Kubernetes clusters. When it comes to logging in Kubernetes, there are three options with progressively increasing complexity. Basic container level logging for logs generated by applications. Logging at node level that also includes capturing logs generated by Kubernetes' core components. And logging at cluster level that is enabled with an external backend solution. Applications write their logs to standard output instead of to any specific log file. By using kubectl logs command, you can see the logs from a current or a previously running container. In addition to container logs, Kubernetes' native components generate logs as well. These logs can be sent to either journal D or directly to a log file. Cluster level logging relies on implementing a logging backend. In a typical implementation, you will see a node agent running on every node. A common example of a node agent is fluent D. Fluent D is a log aggregator that can ingest logs from different types of log sources. Node aggregator then pushes to a centralized logging backend. Again, a popular choice is a combination of Elasticsearch and Kibana. Though logging is essential, it is of no use if you don't monitor and look for abnormalities and patterns in data. You can connect your logging infrastructure to Prometheus, which is an open source monitoring system. Your enterprise may already be using it. Another monitoring choice is via Splunk, which is also a popular enterprise grade event collection and monitoring solution. And lastly, you can push your logs and events to your centralized SIEM, that is the security information and event management system. This will allow your security teams to view events from Kubernetes alongside other events from the rest of your infrastructure. A single pane of view will help them make a more judicious decision about any security issues.



