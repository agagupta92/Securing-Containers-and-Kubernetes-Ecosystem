
What are containers?

Selecting transcript lines in this section will navigate to timestamp in the video
- [Instructor] A container is a software that packages not only your application code, but also its dependencies such as libraries, configuration settings, and the file system. Containers are portable, meaning they can run on different kinds of operating systems and infrastructure, seamlessly. They isolate a running application from the environment outside the application, as well as from the other containers. Now it's important to realize the difference between a container and a container image. A container image is a special file, that becomes a container when it is run as a process of an operating system. So before we jump into the technology behind the containers, let's take a look at the reasons why you use them. First, the economics, containers are more bang for your buck. Look, if you're running only one operating system, all running containers utilize the same OS and that makes containers lightweight compared to a virtual machine. So when a given hardware setup, you can squeeze a larger number of business applications, since all the dependencies required for an application are packaged along with your code. You don't run into the issue of it works in my laptop, but not in production. Containers are portable across platforms. It is easier to build and share container images in comparison to virtual machine images, given that images are built in layers, they offer observability all the way from the OS to the application layer. When implemented with the right set of security controls, containers limit the spillover should a containerized application be breached, but the security of containers depend upon correctly using the features and isolation capabilities of an operating system. Containers take advantage of an operating system paradigm, known as OS Virtualization. OS Virtualization is made possible, by the capabilities of the kernel of the OS. These capabilities make a running application pink as if it has got a full copy of the OS only to itself. But in reality, multiple applications are sharing the same operating system. This kind of virtualization plays a significant role in the security of containers and the applications running inside them. That's why, it's worth while to review and compare it with other virtualization techniques.

Virtualization

Selecting transcript lines in this section will navigate to timestamp in the video
- [Instructor] At its core, there are three ways applications and their operating environment can be configured on a given hardware. On bare metal, using hardware virtualization, or using OS virtualization. Before virtualization technologies were in mainstream, an application was deployed on a dedicated, bare metal hardware. There were no restrictions on the resources an application could use. Should an application hog the entire hardware resource, the only option left for the admin was to throw more hardware at it. Of course, the applications running on separate hardware were isolated from each other, which was great from a security perspective, but the applications running on the same hardware had limited security boundaries around them. Then came hardware virtualization, which enabled organizations to run multiple virtual machines on the same hardware instance. This form of virtualization not only allowed flexible scale up or scale down of the VMs, but also provided stronger isolation among applications running on the same hardware. Think of each VM as a standalone computer with its own instance of an operating system. The operating system running in the VM thinks it has the full compute and memory resources at its disposal. The OS doesn't know that the hardware is actually being shared with other VMs. And this magic is made possible by the hypervisor layer. As an industry, we could have stopped right there. Don't get me wrong. VM based deployments do provide isolation and scalability. In fact, they work really well for a variety of use cases. But, modern loosely coupled microservices that are built, deployed and restarted many times during the day have different requirements. Enter OS virtualization that made containers possible. Containers are lightweight, easy to create and destroy and don't come with the overhead associated with the virtual machines. This makes them more suitable for the modern applications and use cases. On the surface containers appear similar to VMs, but remember behind the scenes, it is the operating system and not the hardware that is being virtualized. Meaning in hardware virtualization, where each VM runs its own copy of an operating system, in OS virtualization only one instance of the operating system is running. Each container thinks it has the entire operating system at its disposal. The container does not know that the operating system is being shared with other containers. What is analogous to the hypervisor from the hardware virtualization in the OS virtualization world? It is the container runtime and the capabilities of the operating system that makes the OS virtualization possible. Let's take a look at the native isolation and security features of the Linux operating system.

Container runtime :

- So now we recognize the security and isolation features offered by the operating system and how essential they are for a container platform. The component that actually leverages these OS features is known as container runtime. Let's now take a look at the role of container runtime within the context of a container platform, such as Docker. We will cover the container images and container orchestration in the later sections of this course. Container platform consists of a Daemon that listens to API requests from the clients. This demon, in turn relies on a component known as container runtime. The definition and the scope of container runtimes have changed over the years. But in general, container runtimes perform two distinct tasks. The high level tasks of image transport, packing or unpacking images is done by so-called high-level Container runtime. In the Docker ecosystem, this task is performed by container D. There are other implementations as well, such as CRI-O. High level container runtime relies on a low-level container runtime to actually run the containers. Low-level container runtime uses operating system features such as namespaces and cgroups to create and isolate containers. RunC is the most popular implementation of a low level container runtime. Keep in mind that there are some implementations of container runtimes that perform both the high level and the low level functionalities. For example, RKT also known as rocket. While we are talking about containers, it is important to know about the Open Container Initiative or in short the OCI. OCI is a project under Linux foundation that standardizes to specifications related to containers and container images. OCI image specification defines a standard way of creating a container image. While OCI runtime specification defines a standard way of running an ACI image. Now let's connect back to our diagram. RunC is an OCI runtime spec compliant implementation while container D leverages the OCI image specification.